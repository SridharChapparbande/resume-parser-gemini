{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Method 1 - using transformer model(google gemini pro flash model)"
      ],
      "metadata": {
        "id": "tMOVmbvKxusr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating the previous version\n",
        "!pip install --upgrade google-generativeai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WLMuw9sllYTc",
        "outputId": "e0a45ff3-2c25-4952-cf97-7b0f9fb51c1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.174.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing all the required libraries\n",
        "!pip install google-generativeai PyPDF2 pandas python-docx -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xuEYn90VlYQE",
        "outputId": "b530ccf8-66b0-4fb6-badf-56014b2008ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the libraries for working\n",
        "import os # for os related like accessing credentials, filepath\n",
        "import google.generativeai as genai # Google's generative model(gemini pro)\n",
        "from PyPDF2 import PdfReader # for reading the pdf file\n",
        "\n",
        "# Load your Gemini API key\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyBPeixsCPxffFDAbIQajSVa-CLd_WL5LwE\"  # NOTE: This API key will be deleted after sharing\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"]) # setting up the environment\n"
      ],
      "metadata": {
        "id": "y6GwH93dlbzw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document  # for docx file reader\n",
        "\n",
        "# Function for extracting the raw text from sample resume files(Pdf, docx)\n",
        "def extract_text_from_file(file_path):\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "    if ext == \".pdf\":\n",
        "        reader = PdfReader(file_path)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text.strip()\n",
        "\n",
        "    elif ext == \".docx\":\n",
        "        doc = Document(file_path)\n",
        "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "        return text.strip()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Only .pdf and .docx are supported.\")\n",
        "\n",
        "# Calling funtion for preview\n",
        "resume_text = extract_text_from_file(\"/content/sample_resume.pdf\")  # or .docx\n",
        "print(\"Preview:\\n\", resume_text[:800])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OjeK6erCljhD",
        "outputId": "da1b1d63-3f40-4dad-a2f4-13f6c8eea142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Preview:\n",
            " Vijay Pagare\n",
            "(+91)889XXXXX2 8 | xyz@gmail.com | Miraroad, Thane, MH, IND https://\n",
            "www.linkedin.com/in/xyz/\n",
            "Afrontend-leaningsoftwareengineerwhohas4.5+yearsofexperienceinbuildingandmaintaininghigh-quality(B2B)\n",
            "saasproductsandwebapplications.Provenabilitytoworkindependentlyandaspartofateaminfast-moving,\n",
            "resource-constraintenvironmentswhereshortturnaroundtimesareanorm.Exceptionalatleveraginginterpersonalskills\n",
            "tofacilitateacollaborativerelationshipamongcross-functionalteamstogettheworkdone.Excellentproblem-solverwith\n",
            "anaptitudefortroubleshootingandtheabilitytoquicklymasternewskills,technology,orarole.\n",
            "PROFESSIONAL EXPERIENCE\n",
            "PROPELLOR.AI\n",
            "Software Engineer - FrontendPune - Remote\n",
            "August2021‚ÄìPresent\n",
            "‚óèArchitected, built and maintained business critical modules for a data uni\u0000\u0000cation and visualis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the prompt as per the model required for the gemini model\n",
        "# Prompt is created as the requirement on what to extract from the file\n",
        "\n",
        "def build_resume_prompt(resume_text):\n",
        "    return f\"\"\"\n",
        "You are a professional resume parser. Extract the following information and return only a valid JSON object with no explanations or extra formatting:\n",
        "\n",
        "Resume Text:\n",
        "\\\"\\\"\\\"\n",
        "{resume_text}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Return JSON with the following fields:\n",
        "- full_name\n",
        "- email\n",
        "- phone\n",
        "- linkedin\n",
        "- github\n",
        "- skills (list)\n",
        "- education (list of {{degree, institution, year}})\n",
        "- work_experience (list of {{title, company, start_year, end_year, description}})\n",
        "- certifications (list)\n",
        "- languages (list)\n",
        "- summary (string)\n",
        "\n",
        "Only return pure valid JSON. No markdown. No explanations.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "-zsn1K3XnjIi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model loading and initilizing using gemini-1.5-flash as it is small model\n",
        "def extract_resume_json(prompt):\n",
        "    model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")\n",
        "    response = model.generate_content([prompt])\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "OEeLtCcNnlHL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final calling of all functions defined above\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Run the full chain\n",
        "prompt = build_resume_prompt(resume_text)\n",
        "response = extract_resume_json(prompt)\n",
        "\n",
        "#For reference on how the model is working\n",
        "print(\"Raw Gemini Output:\\n\", response)\n",
        "\n",
        "# Parsing JSON\n",
        "try:\n",
        "    clean_output = response.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "    parsed = json.loads(clean_output)\n",
        "\n",
        "    # Pretty print\n",
        "    print(\"\\nFinal Parsed JSON:\")\n",
        "    print(json.dumps(parsed, indent=4))\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Failed to parse JSON:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j1QpHxTannCr",
        "outputId": "f1d66122-4443-413e-94a3-3a83d0b0dfa9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Gemini Output:\n",
            " ```json\n",
            "{\n",
            "  \"full_name\": \"Vijay Pagare\",\n",
            "  \"email\": \"xyz@gmail.com\",\n",
            "  \"phone\": \"+91889XXXXX28\",\n",
            "  \"linkedin\": \"https://www.linkedin.com/in/xyz/\",\n",
            "  \"github\": null,\n",
            "  \"skills\": [\n",
            "    \"Javascript\",\n",
            "    \"Typescript\",\n",
            "    \"React\",\n",
            "    \"NextJS\",\n",
            "    \"Angular\",\n",
            "    \"Tailwind CSS\",\n",
            "    \"HTML\",\n",
            "    \"CSS/SCSS\",\n",
            "    \"Git\",\n",
            "    \"REST APIs\",\n",
            "    \"Nodejs\",\n",
            "    \"Linux\",\n",
            "    \"Material Design\",\n",
            "    \"Ant Design\",\n",
            "    \"ES6\",\n",
            "    \"Redux\",\n",
            "    \"RxJS\",\n",
            "    \"Apache Echarts\",\n",
            "    \"D3.js\",\n",
            "    \"Three.js\",\n",
            "    \"Sockets\",\n",
            "    \"PWA\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Bachelor of Engineering - Computers\",\n",
            "      \"institution\": \"Rajiv Gandhi Institute of Technology, Mumbai University\",\n",
            "      \"year\": 2019\n",
            "    }\n",
            "  ],\n",
            "  \"work_experience\": [\n",
            "    {\n",
            "      \"title\": \"Software Engineer - Frontend\",\n",
            "      \"company\": \"PROPELLOR.AI\",\n",
            "      \"start_year\": 2021,\n",
            "      \"end_year\": null,\n",
            "      \"description\": \"Architected, built and maintained business critical modules for a data unification and visualisation platform. Introduced 20+ charts including sankey, wordcloud, heatmap, tree, bubble, Map - India and USA, with a few custom bar charts & tables. Built them using SVG, Canvas, and Open-source libraries like Apache Echarts, d3, ng-zorro, and ag-grid. Developed 10+ data sources by integrating 3rd party APIs from facebook, google, shopify, snapchat, etc. Built data connectors using forms and oAuth2 based approaches. Implemented features: ticketing system, billing service, user management, rich-text-editor enabled notes, admin panel, RBACs & Tier-Based User Restriction Service, chart alerts, dashboard and charting related - page & group filters, external share, save as pdf, slideshow mode. Stabilised the app by reducing the bugs by 90% within a quarter of joining and thereon maintained a <5% bug-to-new-feature ratio. Redesigned API responses by making proper use of cohesion and coupling concepts. Refactored the centralised state management service where RxJS leaks were prominent. Built a tracking service that could facilitate Root Cause Analysis for high-impact causing issues by logging the user actions, code flow, and modifications in the source-of-truth. Established an AWS pipeline for dev, stage, and prod environments to automate releases. Set up a release and sign-off process in place. Enhanced the User Experience and Interface which led to a doubling of the average time spent on the app and improved demo-to-trial ratio. Prepared a UX + lighthouse report along with the design team wherein we identified some quick wins and established other long-term procedures as a part of design sign-off process. Implemented driver.js for product demos instead of video onboarding, introduced setup guides, help, and getting started CTAs, brought in micro-interactions, changed the entire app theme along with the component library, and coordinated with designers for improved user messaging. Made sure we paid attention to details - alignments, spacing, color combos, adherence to design principles, etc. Took lighthouse accessibility and best practices scores to around 90 from below 60. Revamped the architecture of the core charting library and dashboard module to improve the first contentful paint time from 5s to 1.5s. Did so by modularising the code into smaller chunks (modules and components), refactored memory leaks, reduced unnecessary API calls, performed asset compression and caching + enabled CDNs. Implemented lazy loading and lazy rendering (render stuff only when necessary-strategic breaking down of the entire page into groups). Cleaned up redundant services, unused components, packages, images and other assets. Led migration from angular v9 to v15 along with all its dependencies. Took the lighthouse performance score from around 25 to 70. Single-handedly leading the frontend development activities since Jan 2023. Active contributions in project planning and product discussions. Accustomed to working alongside the CEO, CTO along with fellow engineers and designers.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Software Engineer - Founder\",\n",
            "      \"company\": \"ERAGAP VENTURES\",\n",
            "      \"start_year\": 2020,\n",
            "      \"end_year\": 2021,\n",
            "      \"description\": \"Indie-hacked a portfolio of products and services as a solopreneur. Mostly worked on web-based SaaS tools, media initiatives, and client projects. Made multiple pivots: ecom, crypto, and content. Built ecom apps for a jewellery store and a paper florist using React/NextJS, Tailwind CSS, Javascript, and Vercel. Developed a web app that provided legal documents service (wills & codicils). Built an SEO-rich blog app for creators that converted .md files to blog posts. Built a content automation platform (app+website) to help creators and marketers automate social media posts. Data once connected to Google Sheets would turn into ready-to-post images. Built a philosophy-based app like Goodreads + inshorts app, later turned into a content-only product. Social media peak reached an average of 100K monthly impressions for 6 months.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Software Engineer - Frontend\",\n",
            "      \"company\": \"FLEXILOANS\",\n",
            "      \"start_year\": 2019,\n",
            "      \"end_year\": 2020,\n",
            "      \"description\": \"Built a dynamic client onboarding and lead generation platform (JSON-based) that tailored itself to various user journeys depending upon the source of the lead and was integrated with Flexiloans' business partners like Gpay, Paypal, and Xiaomi. It was used by 6 lac SMEs per month. Awarded Employee of the Month twice. Features: KYC flow, Loans Profile Section, E-Nach/Ops flow.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Lecturer - Founder\",\n",
            "      \"company\": \"LUMINAIRE ACADEMY\",\n",
            "      \"start_year\": 2015,\n",
            "      \"end_year\": 2019,\n",
            "      \"description\": \"Bootstrapped an online coaching institute during my college days. ARR: 15 lac. Roles: Teaching (physics), guest lecturing at other partner institutes (5+), mentoring. Prime decision-making, marketing and revenue generation.\"\n",
            "    }\n",
            "  ],\n",
            "  \"certifications\": [],\n",
            "  \"languages\": [],\n",
            "  \"summary\": \"A frontend-leaning software engineer who has 4.5+ years of experience in building and maintaining high-quality (B2B) SaaS products and web applications. Proven ability to work independently and as part of a team in fast-moving, resource-constrained environments where short turnaround times are a norm. Exceptional at leveraging interpersonal skills to facilitate a collaborative relationship among cross-functional teams to get the work done. Excellent problem-solver with an aptitude for troubleshooting and the ability to quickly master new skills, technology, or role.\"\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "Final Parsed JSON:\n",
            "{\n",
            "    \"full_name\": \"Vijay Pagare\",\n",
            "    \"email\": \"xyz@gmail.com\",\n",
            "    \"phone\": \"+91889XXXXX28\",\n",
            "    \"linkedin\": \"https://www.linkedin.com/in/xyz/\",\n",
            "    \"github\": null,\n",
            "    \"skills\": [\n",
            "        \"Javascript\",\n",
            "        \"Typescript\",\n",
            "        \"React\",\n",
            "        \"NextJS\",\n",
            "        \"Angular\",\n",
            "        \"Tailwind CSS\",\n",
            "        \"HTML\",\n",
            "        \"CSS/SCSS\",\n",
            "        \"Git\",\n",
            "        \"REST APIs\",\n",
            "        \"Nodejs\",\n",
            "        \"Linux\",\n",
            "        \"Material Design\",\n",
            "        \"Ant Design\",\n",
            "        \"ES6\",\n",
            "        \"Redux\",\n",
            "        \"RxJS\",\n",
            "        \"Apache Echarts\",\n",
            "        \"D3.js\",\n",
            "        \"Three.js\",\n",
            "        \"Sockets\",\n",
            "        \"PWA\"\n",
            "    ],\n",
            "    \"education\": [\n",
            "        {\n",
            "            \"degree\": \"Bachelor of Engineering - Computers\",\n",
            "            \"institution\": \"Rajiv Gandhi Institute of Technology, Mumbai University\",\n",
            "            \"year\": 2019\n",
            "        }\n",
            "    ],\n",
            "    \"work_experience\": [\n",
            "        {\n",
            "            \"title\": \"Software Engineer - Frontend\",\n",
            "            \"company\": \"PROPELLOR.AI\",\n",
            "            \"start_year\": 2021,\n",
            "            \"end_year\": null,\n",
            "            \"description\": \"Architected, built and maintained business critical modules for a data unification and visualisation platform. Introduced 20+ charts including sankey, wordcloud, heatmap, tree, bubble, Map - India and USA, with a few custom bar charts & tables. Built them using SVG, Canvas, and Open-source libraries like Apache Echarts, d3, ng-zorro, and ag-grid. Developed 10+ data sources by integrating 3rd party APIs from facebook, google, shopify, snapchat, etc. Built data connectors using forms and oAuth2 based approaches. Implemented features: ticketing system, billing service, user management, rich-text-editor enabled notes, admin panel, RBACs & Tier-Based User Restriction Service, chart alerts, dashboard and charting related - page & group filters, external share, save as pdf, slideshow mode. Stabilised the app by reducing the bugs by 90% within a quarter of joining and thereon maintained a <5% bug-to-new-feature ratio. Redesigned API responses by making proper use of cohesion and coupling concepts. Refactored the centralised state management service where RxJS leaks were prominent. Built a tracking service that could facilitate Root Cause Analysis for high-impact causing issues by logging the user actions, code flow, and modifications in the source-of-truth. Established an AWS pipeline for dev, stage, and prod environments to automate releases. Set up a release and sign-off process in place. Enhanced the User Experience and Interface which led to a doubling of the average time spent on the app and improved demo-to-trial ratio. Prepared a UX + lighthouse report along with the design team wherein we identified some quick wins and established other long-term procedures as a part of design sign-off process. Implemented driver.js for product demos instead of video onboarding, introduced setup guides, help, and getting started CTAs, brought in micro-interactions, changed the entire app theme along with the component library, and coordinated with designers for improved user messaging. Made sure we paid attention to details - alignments, spacing, color combos, adherence to design principles, etc. Took lighthouse accessibility and best practices scores to around 90 from below 60. Revamped the architecture of the core charting library and dashboard module to improve the first contentful paint time from 5s to 1.5s. Did so by modularising the code into smaller chunks (modules and components), refactored memory leaks, reduced unnecessary API calls, performed asset compression and caching + enabled CDNs. Implemented lazy loading and lazy rendering (render stuff only when necessary-strategic breaking down of the entire page into groups). Cleaned up redundant services, unused components, packages, images and other assets. Led migration from angular v9 to v15 along with all its dependencies. Took the lighthouse performance score from around 25 to 70. Single-handedly leading the frontend development activities since Jan 2023. Active contributions in project planning and product discussions. Accustomed to working alongside the CEO, CTO along with fellow engineers and designers.\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"Software Engineer - Founder\",\n",
            "            \"company\": \"ERAGAP VENTURES\",\n",
            "            \"start_year\": 2020,\n",
            "            \"end_year\": 2021,\n",
            "            \"description\": \"Indie-hacked a portfolio of products and services as a solopreneur. Mostly worked on web-based SaaS tools, media initiatives, and client projects. Made multiple pivots: ecom, crypto, and content. Built ecom apps for a jewellery store and a paper florist using React/NextJS, Tailwind CSS, Javascript, and Vercel. Developed a web app that provided legal documents service (wills & codicils). Built an SEO-rich blog app for creators that converted .md files to blog posts. Built a content automation platform (app+website) to help creators and marketers automate social media posts. Data once connected to Google Sheets would turn into ready-to-post images. Built a philosophy-based app like Goodreads + inshorts app, later turned into a content-only product. Social media peak reached an average of 100K monthly impressions for 6 months.\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"Software Engineer - Frontend\",\n",
            "            \"company\": \"FLEXILOANS\",\n",
            "            \"start_year\": 2019,\n",
            "            \"end_year\": 2020,\n",
            "            \"description\": \"Built a dynamic client onboarding and lead generation platform (JSON-based) that tailored itself to various user journeys depending upon the source of the lead and was integrated with Flexiloans' business partners like Gpay, Paypal, and Xiaomi. It was used by 6 lac SMEs per month. Awarded Employee of the Month twice. Features: KYC flow, Loans Profile Section, E-Nach/Ops flow.\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"Lecturer - Founder\",\n",
            "            \"company\": \"LUMINAIRE ACADEMY\",\n",
            "            \"start_year\": 2015,\n",
            "            \"end_year\": 2019,\n",
            "            \"description\": \"Bootstrapped an online coaching institute during my college days. ARR: 15 lac. Roles: Teaching (physics), guest lecturing at other partner institutes (5+), mentoring. Prime decision-making, marketing and revenue generation.\"\n",
            "        }\n",
            "    ],\n",
            "    \"certifications\": [],\n",
            "    \"languages\": [],\n",
            "    \"summary\": \"A frontend-leaning software engineer who has 4.5+ years of experience in building and maintaining high-quality (B2B) SaaS products and web applications. Proven ability to work independently and as part of a team in fast-moving, resource-constrained environments where short turnaround times are a norm. Exceptional at leveraging interpersonal skills to facilitate a collaborative relationship among cross-functional teams to get the work done. Excellent problem-solver with an aptitude for troubleshooting and the ability to quickly master new skills, technology, or role.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NSoMMMp0lYcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_m2gfOmlYfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2 - Using transformer(NER-spacy model) + Python Regex"
      ],
      "metadata": {
        "id": "meA3OkUA0iL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the required libraries\n",
        "import pdfplumber\n",
        "import spacy # transformer model\n",
        "import re # for regex using pattern\n",
        "import json"
      ],
      "metadata": {
        "id": "3VoNzG8C4kpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline # hugging face transformer library\n",
        "\n",
        "# Load BERT-based NER model\n",
        "model_name = \"dslim/bert-base-NER\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n"
      ],
      "metadata": {
        "id": "iuIXQ-KK0Uo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For extracting the text from file\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = ''\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + '\\n'\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "4xw9bhx50XvE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For extracting ner entities which are supported by NER model\n",
        "def extract_ner_entities(text):\n",
        "    entities = ner_pipeline(text)\n",
        "    structured = {\"PER\": [], \"ORG\": [], \"LOC\": [], \"DATE\": [], \"MISC\": []}\n",
        "    for ent in entities:\n",
        "        group = ent[\"entity_group\"]\n",
        "        if group in structured:\n",
        "            structured[group].append(ent[\"word\"])\n",
        "    for key in structured:\n",
        "        structured[key] = list(dict.fromkeys(structured[key]))\n",
        "    return structured\n"
      ],
      "metadata": {
        "id": "EL6bZKBI0ar4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For extracting the sections like experience, skills etc\n",
        "def split_sections(text):\n",
        "    sections = {\n",
        "        \"summary\": \"\",\n",
        "        \"work_experience\": \"\",\n",
        "        \"education\": \"\",\n",
        "        \"skills\": \"\"\n",
        "    }\n",
        "    current_section = \"summary\"\n",
        "    for line in text.splitlines():\n",
        "        line_lower = line.strip().lower()\n",
        "        if \"experience\" in line_lower and \"project\" not in line_lower:\n",
        "            current_section = \"work_experience\"\n",
        "        elif \"education\" in line_lower:\n",
        "            current_section = \"education\"\n",
        "        elif \"skills\" in line_lower or \"tech stack\" in line_lower:\n",
        "            current_section = \"skills\"\n",
        "        else:\n",
        "            sections[current_section] += line.strip() + \"\\n\"\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "DmsrwIRb0apC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For extracting the personal info\n",
        "def extract_contact_info_and_summary(text):\n",
        "    email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
        "    phone_match = re.search(r'(\\+91[\\s\\-]?)?[0]?[789]\\d{9}', text)\n",
        "    email = email_match.group() if email_match else \"\"\n",
        "    phone = phone_match.group() if phone_match else \"\"\n",
        "\n",
        "    lines = text.strip().split(\"\\n\")\n",
        "    summary = \"\"\n",
        "    for i in range(5, len(lines)):\n",
        "        if len(lines[i].strip()) > 40:\n",
        "            summary = lines[i].strip()\n",
        "            break\n",
        "\n",
        "    address = {\n",
        "        \"city\": \"thane\" if \"thane\" in text.lower() else \"mumbai\",\n",
        "        \"state\": \"mh\",\n",
        "        \"country\": \"ind\"\n",
        "    }\n",
        "\n",
        "    return email, phone, address, summary\n"
      ],
      "metadata": {
        "id": "xnp_CIu_0ajf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For extracting work experience\n",
        "def extract_work_experience(text):\n",
        "    work_entries = []\n",
        "    jobs = re.split(r\"\\n(?=[A-Z].+?[-‚Äì].+?)\", text)\n",
        "    for block in jobs:\n",
        "        lines = [l.strip() for l in block.strip().split(\"\\n\") if l.strip()]\n",
        "        if len(lines) < 2:\n",
        "            continue\n",
        "        title = lines[0]\n",
        "        company = lines[1]\n",
        "        description = \" \".join(lines[2:]) if len(lines) > 2 else \"\"\n",
        "        from_date, to_date = \" \", \" \"\n",
        "        date_match = re.findall(r'([A-Za-z]+\\s?\\d{4})\\s?[‚Äì-]\\s?(Present|\\w+\\s?\\d{4})', block)\n",
        "        if date_match:\n",
        "            from_date, to_date = date_match[0]\n",
        "        work_entries.append({\n",
        "            \"company\": company.lower(),\n",
        "            \"title\": title.lower(),\n",
        "            \"from_date\": from_date,\n",
        "            \"to_date\": to_date,\n",
        "            \"description\": description\n",
        "        })\n",
        "    return work_entries\n"
      ],
      "metadata": {
        "id": "9oWqxvrw0abs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For extracting the skills\n",
        "def extract_skills(text):\n",
        "    skill_section = re.findall(r'(TECH\\s?STACK|Skills)[\\s:\\-]*([\\s\\S]+?)(Education|Projects|Certifications|$)', text, re.IGNORECASE)\n",
        "    if skill_section:\n",
        "        raw_skills = skill_section[0][1]\n",
        "        skills = re.split(r\"[,\\n]\", raw_skills)\n",
        "        return [{\"skill\": s.strip().lower()} for s in skills if s.strip()]\n",
        "    return []\n"
      ],
      "metadata": {
        "id": "Ba8lIqId0aYy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final call for all the defined functions above\n",
        "def parse_resume(text):\n",
        "    ner = extract_ner_entities(text)\n",
        "    sections = split_sections(text)\n",
        "    name = ner[\"PER\"][0].split() if ner[\"PER\"] else [\"\", \"\"]\n",
        "    first_name = name[0].lower()\n",
        "    last_name = name[-1].lower() if len(name) > 1 else \"\"\n",
        "\n",
        "    email, phone, address, summary = extract_contact_info_and_summary(text)\n",
        "    education = extract_education(sections[\"education\"])\n",
        "    work = extract_work_experience(sections[\"work_experience\"])\n",
        "    skills = extract_skills(text)\n",
        "\n",
        "    return {\n",
        "        \"first_name\": first_name,\n",
        "        \"last_name\": last_name,\n",
        "        \"email\": email,\n",
        "        \"phone\": phone,\n",
        "        \"address\": {\n",
        "            \"city\": address[\"city\"].lower(),\n",
        "            \"state\": address[\"state\"].lower(),\n",
        "            \"country\": address[\"country\"].lower()\n",
        "        },\n",
        "        \"summary\": summary,\n",
        "        \"education_history\": education,\n",
        "        \"work_history\": work,\n",
        "        \"skills\": skills\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ewoUHk7n0aVe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing using the given sample resume\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/sample_resume.pdf\"\n",
        "    resume_text = extract_text_from_pdf(file_path)\n",
        "    parsed_output = parse_resume(resume_text)\n",
        "\n",
        "    with open(\"parsed_output.json\", \"w\") as f:\n",
        "        json.dump(parsed_output, f, indent=4)\n",
        "\n",
        "    print(\"‚úÖ Resume parsed successfully. Output saved to parsed_output.json\")\n"
      ],
      "metadata": {
        "id": "iplHndjj0aPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}